{
    "name": "base", // experiments name
    "gpu_ids": [ // gpu ids list, default is single 0
        0 
    ],
    "seed" : 2022, // random seed
    "finetune_norm": false, // find the parameters to optimize
    "path": { //set every part file root
        "log": "logs", // root of progress logs (logging) 
        "tb_logger": "tb_logger", // root of tensorboard logger
        "results": "results",
        "checkpoint": "checkpoint",
        // "resume_state": "experiments/debug_base_220210_165430/checkpoint/36"
        "resume_state": null // ex: 10000, loading .state  and _net.pth from given iterations
    },
    "datasets": { // train|val|test, None part will be skip
        "train": {
            "name": "image_dataset", // use which dataset, indicates dataset's file name
            "root": "/data/jlw/datasets/comofod",
            "batch_size": 2, // batch size in every gpu
            "num_workers": 8,
            "use_shuffle": true,
            "pin_memory": true,
            "data_len": -1 // -1 represents all data used in train
        },
        "val": {
            "name": "image_dataset",
            "root": "/data/jlw/datasets/comofod",
            "batch_size": 1,
            "num_workers": 4,
            "pin_memory": true,
            "data_len": 50
        },
        "test": { // to do 
            
        }
    },
    "model": {
        "which_model": "ae", // use which trainer, indicates trainer's file name in models path
        "which_module": "ae" // use which model structure, indicates structure's file name in models/modules path
    },
    "train": {
        "n_iter": 1000000, // max iterations
        "n_epoch": 1e5, // max epochs, not limited now
        
        "val_freq": 1e5, // valdation each number of interval samples 
        "save_checkpoint_freq": 1e5,
        "display_freq": 1e4,
        "print_freq": 1e3
    }
}